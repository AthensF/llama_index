{"docstore/metadata": {"dc691d0f-d47d-499b-97f3-1ec02360044b": {"doc_hash": "45629127ed6d1072d51b70d15f999d17c3fa1bedf240e63be4111fa04ba85a4e"}, "b0ac782b-ce0a-4802-b44a-16bb40bf2b79": {"doc_hash": "4b54f9aab5502bbad6ab34ef162ce42de22b559424adea3870d8a26ad2835f57"}, "7689ead5-3d1c-4aef-b1c7-636ce422af6e": {"doc_hash": "83fac56729f2662a7e93ab4068eaae3578dd5c6a0767a1f03cce760b5379690f"}, "3c413978-c847-4d57-9f27-b86aca205185": {"doc_hash": "8f2559df4945e80ce963103878c2444341a77a909807f17d42bd5b4bd7a9b290"}, "c5e69acb-f870-48a5-aec9-25d6fc1954c9": {"doc_hash": "989fb5d910896025c1170a2777d5f25c4fe86287475540b2b7cc5da9531da61f"}, "b4e6e4be-4681-4f2a-b502-e3b1d2aeb1c3": {"doc_hash": "72943ba14da6a17840d909d9df03efc27b56418340c1a7b71fc67b11134624da"}, "f1391247-e63a-401c-8d6d-3af522e52738": {"doc_hash": "d021ad52e3ce55391f15965c2cbfdddd79479331b9edb335717015c82689dfd2"}, "808b7731-8096-4c64-9a9f-ed269188e5e0": {"doc_hash": "5b456a8067f60a2566e3080ebb0a9cf3d54c2b3c9508f743b2a4777a75cb4159"}}, "docstore/data": {"b0ac782b-ce0a-4802-b44a-16bb40bf2b79": {"__data__": {"text": "Tamr Mastering\nUsing our expert-trained machine learning (ML) algorithms, our data mastering software consolidates, cleans, and categorizes your internal and external data sources to power the insights that your company needs.\n\nReplace your human-intensive processes with a machine learning-first, human in the loop data management model that can scale as your business grows.\n\nHow our data mastering solution works\nTamr Mastering uses a machine learning-first approach so you can maximize the impact of business rules and human curation to get trusted, high quality data without a multi-year master data management initiative.\n\nStart by choosing from a catalog of Data products designed by Tamr\u2019s expert data scientists. Each Data product includes pre-trained machine learning models, data enrichment, a recommended schema, and record consolidation logic, Tamr then helps you test, validate, and refine your mastering pipeline so you\u2019re consuming data that meets business requirements. The outcome \u2014 90% less time spent manually improving data quality, and new business insights to drive revenue, cost savings, and risk reduction. Take a look at our ROI calculator to see how much profit our data mastering tool can deliver for you.\n\nThanks to our numerous partnerships and integrations, Tamr\u2019s data mastering tool seamlessly integrates with the tools you already use to get you business insights from your data faster, to everyone in your company who needs it.\n\nDeliver clean data in the form the business needs it.\nYou own your data. Most external match services and traditional data quality systems use rules to establish unified records. The results are often rigid and impractical. With Tamr Cloud, you\u2019re in control of how your data is mastered.\n\nCreate Golden Records\nCreate a complete view of customer information and assign a unique ID as a consistent identifier and single source of truth.\n\nUnderstand Hierarchies\nFlexibility to classify customers based on how you manage customers, from sites and sales regions to corporate hierarchies.\n\nTamr Technical Whitepaper\n1. Executive Summary\nTamr was founded to tackle large-scale data management challenges in\norganizations where extreme data volume and variety require an approach\ndifferent from legacy technologies. Whereas most traditional solutions focus on\ntop-down, rules-based methods for managing data, Tamr focuses on a bottomup, machine learning-based approach to unifying disparate, dirty datasets within\nan organization.\nTamr\u2019s enterprise data uniication method combines machine learning and human expert guidance to unify data\nsources across an organization with unmatched speed, scalability, and accuracy. The platform\u2019s core capabilities\ninclude \u201cconnecting\u201d data sources across an organization to align relevant datasets to a uniied schema,\n\u201ccleaning\u201d the uniied dataset through entity deduplication and mastering, and \u201cclassifying\u201d records within the\nclean, uniied dataset to a client-provided taxonomy for more robust downstream analysis. The resulting dataset\ncan be consumed by multiple endpoints - from analytic tools to data warehouses - and this enables Tamr to be a\nvery complementary data management technology to legacy solutions (such as MDM and ETL) as well as newer\ntechnologies (such as Data Catalogs, Self-Service Data Preparation Tools, and Analytic Tools). Ultimately, enterprise\ndata uniication is a proven need across a variety of use cases as well as industries and Tamr has been able to\nunlock signiicant value for customers - to the tune of hundreds of millions of dollars - through its implementation\nin these complex environments.\n2. Tamr Product Overview\na. Company Background\nFounded in 2013, Tamr was launched by start-up collaborators and data management veterans Andy Palmer\nand Mike Stonebraker. The two had previously co-founded Vertica Systems (a high performance database\nmanagement company that sold to HP for $350M) and worked together on several other related companies. Their\nshared experiences forged a common belief that the core ideas behind the last 20+ years of data management\nthinking were failing to meet the needs of today\u2019s enterprises. With the", "doc_id": "b0ac782b-ce0a-4802-b44a-16bb40bf2b79", "embedding": null, "doc_hash": "4b54f9aab5502bbad6ab34ef162ce42de22b559424adea3870d8a26ad2835f57", "extra_info": null, "node_info": {"start": 0, "end": 4164, "_node_type": "1"}, "relationships": {"1": "dc691d0f-d47d-499b-97f3-1ec02360044b", "3": "7689ead5-3d1c-4aef-b1c7-636ce422af6e"}}, "__type__": "1"}, "7689ead5-3d1c-4aef-b1c7-636ce422af6e": {"__data__": {"text": "management\nthinking were failing to meet the needs of today\u2019s enterprises. With the amount and variety of data available to\nenterprises exploding, traditional methods for organizing it for analytics could no longer keep up. Therefore, in 2012\nthe team began research at MIT\u2019s Computer Science & AI Lab on a bottom-up solution for managing the radical\ndata volume, velocity and, especially, variety in the modern enterprise. The resulting 2013 paper, \u201cData Curation at\nScale: The Data Tamer System,\u201d described a breakthrough approach for combining machine learning and human\nexpert guidance to unify data across thousands of sources. The paper became the guiding vision for Tamr\u2019s\nproduct and was the inluence as to how Tamr acquired its name.\n\nb. Core Capabilities\nTamr is an enterprise data uniication platform whose patented software system combines machine learning\nwith human expertise to automate the uniication of data silos dispersed across large companies -- delivering\npreviously impossible analytic breakthroughs. It\u2019s the only system capable of unifying data at scale and across\ndomains quickly, accurately, and cost-effectively. In order to quickly and accurately prepare data at enterprise\nscale for downstream analysis, Tamr has architected three core capabilities that utilize its patented human-guided\nmachine learning-based approach.\ni. Connect\nThe \u201cconnect\u201d phase starts with a deinition of project goals and identiication of the\nentities (e.g. person, place or thing) the user wants a uniied view of for the purpose\nof downstream analysis. Within the connect phase, Tamr aligns all relevant source\ndataset attributes to a uniied schema that is most effective and relevant for project\ngoals. Human-guided machine learning is employed to union these datasets and offers\na signiicant improvement in speed and scale as compared to traditional methods that\nrely on writing script. Tamr performs this in the following way:\n\u2022 Tamr ingests data from source systems (e.g. databases, HDFS, CSVs and lat iles) via APIs, JDBC\nconnections, or a set of connectors. The Tamr platform requires data to be relatively structured / tagged\nprior to ingestion and can accept data in data formats such as JSON, Multivalues, Tabular, and XML\n\u2022 Datasets from these sources are then proiled so users can identify the logical entity types contained within\neach - such as customers, supplier, etc. - and can assess the quality of their data to ensure its suitable for\nanalysis\n\u2022 Target schemas are then identiied within the Tamr system to ensure the optimal attributes are represented\nin the inal uniied dataset. Users can either select attributes from data sources to build their uniied schema\n\n\nor load in their own schema with samples of values for each attribute\n\u2022 At this stage, Tamr will employ human-guided machine learning to align source dataset attributes to the\nuniied schema\n+ Tamr will irst proile values within the uniied schema as a baseline for comparison. This includes\nmetadata such as ield names, descriptions / annotations, data types, and validations\n+ Tamr then proiles the same information within source attributes and uses unsupervised machine\nlearning to identify potential matches between source and target schema attributes based on an\ninitial model Tamr has generated\n+ In order to validate the accuracy of Tamr\u2019s matches and allow for the system to learn - turning the\ncorner into supervised machine learning - Tamr will produce \u201chigh impact questions\u201d - which are\nsimple yes/no questions about matches between sample attribute pairs from the target schema and\nsource datasets that are highly representative of other potential attribute pairs. For example, if Tamr\nhas low conidence regarding whether or not source attribute \u201cmailing address\u201d is synonymous\nwith uniied attribute \u201cstreet address\u201d, it will ask a user within the client organization for their\nfeedback. This not only drives accuracy into the process to ensure trusted results but also enables\nTamr\u2019s algorithms to learn from the insight so a higher percentage of the next, similar batch of\nattributes are", "doc_id": "7689ead5-3d1c-4aef-b1c7-636ce422af6e", "embedding": null, "doc_hash": "83fac56729f2662a7e93ab4068eaae3578dd5c6a0767a1f03cce760b5379690f", "extra_info": null, "node_info": {"start": 4093, "end": 8182, "_node_type": "1"}, "relationships": {"1": "dc691d0f-d47d-499b-97f3-1ec02360044b", "2": "b0ac782b-ce0a-4802-b44a-16bb40bf2b79", "3": "3c413978-c847-4d57-9f27-b86aca205185"}}, "__type__": "1"}, "3c413978-c847-4d57-9f27-b86aca205185": {"__data__": {"text": "from the insight so a higher percentage of the next, similar batch of\nattributes are matched automatically and without the need for human intervention\n+ The curator operating Tamr will identify subject matter experts within the organization to either\nvalidate or invalidate Tamr\u2019s matches via direct login to the system or out-of-band mechanisms such\nas email. There is no set limit to the amount of experts permitted to use the system\n+ Expert feedback is then incorporated immediately or goes through a worklow to determine the\nappropriate action. For example, when assessing whether or not two attributes are matches, the\nuser may want to incorporate feedback from multiple experts. In this environment, they may want\nto stipulate that the system recognize, for example, the most common yes / no input among the\ngroup of experts assigned to that potential attribute pair\n+ Having incorporated expert feedback, Tamr then reines its model for more automated use in\nthe future\n\u2022 The uniied dataset of a logical entity, incorporating the target schema, is now materialized and able to be\nexported or used in downstream Tamr capabilities\nii. Clean\nTamr\u2019s \u201cclean\u201d phase is designed to deduplicate and master the entities within the\nuniied dataset eficiently and accurately through the use of human-guided machine\nlearning. The issue of dirty, duplicative data across enterprise data systems is extremely\ncommon and a one that is very dificult to solve using conventional data management\ntechniques. The principle function of this phase of Tamr is record linkage --allowing\nusers to identify duplicates and / or groups within the core, uniied dataset and master\nthe records contained within it -- resulting in accurate, complete analysis downstream.\nWithin the cleaning phase of the platform:\n\u2022 Tamr will start with a uniied dataset that is yet to be mastered and likely contains signiicant duplicative\nrecords. If training input regarding identiication of duplicative records is available, Tamr will incorporate that\ninto the model\n\u2022 In a process similar to \u201cconnect\u201d, Tamr will apply human-guided machine learning to the uniied dataset in\norder to cluster or group records that likely relate to the same entity\n+ Unless training data is provided upfront, Tamr will employ unsupervised machine learning to detect\nrecord similarity by analyzing all attributes / attribute values for a pair of records\n+ Tamr will then generate suggestions as to which records may be duplicative based on its modeling\nefforts and generate simple high impact questions regarding record pairs that are representative of\nother potential record pairs in the dataset. For example, if Tamr has low conidence that the person\nreferenced in record \u201cJ. Smith\u201d is the same person referenced in record \u201cJohn S\u201d then it will\nask an expert in the organization who deals with clients to provide feedback as to whether these\nare distinct or matching records. Like the \u201cconnect\u201d phase, this not only drives accuracy into the\nprocess to ensure trusted results but also enables Tamr\u2019s algorithms to learn from the insight so a\nhigher percentage of the next, similar batch of attributes are matched automatically and without the\nneed for human intervention\n\n+ The curator operating Tamr will identify subject matter experts within the organization to either\nvalidate or invalidate Tamr\u2019s matches and then expert feedback is incorporated either immediately or\ngoes through the previously deined worklow to determine the appropriate action\n+ Having incorporated expert feedback, Tamr then reines its model for more automated use in\n the future\n\u2022 For some downstream use cases, grouping clusters of records is suficient for consumption. In other use\ncases, organizations may prefer the groups of records be mastered and merged into a single record. Tamr\u2019s\nmerge logic is robust and includes options for selecting values for attributes within clustered records that\ninclude:\n+ Most common value for an attribute\n+ Value selection from a known \u2018trusted source\u2019 dataset (i.e. a dataset the user knows to be", "doc_id": "3c413978-c847-4d57-9f27-b86aca205185", "embedding": null, "doc_hash": "8f2559df4945e80ce963103878c2444341a77a909807f17d42bd5b4bd7a9b290", "extra_info": null, "node_info": {"start": 8184, "end": 12242, "_node_type": "1"}, "relationships": {"1": "dc691d0f-d47d-499b-97f3-1ec02360044b", "2": "7689ead5-3d1c-4aef-b1c7-636ce422af6e", "3": "c5e69acb-f870-48a5-aec9-25d6fc1954c9"}}, "__type__": "1"}, "c5e69acb-f870-48a5-aec9-25d6fc1954c9": {"__data__": {"text": "dataset (i.e. a dataset the user knows to be most\ntrustworthy)\n+ Steward nominee - where experts can select the appropriate value for a certain attribute\n\u2022 The cleaned, uniied dataset of a logical entity is now materialized and able to be exported or used in\ndownstream Tamr capabilities\niii. Classify\nOnce a clean, uniied dataset of a particular entity has been produced by Tamr, the user\nhas the option of \u201cclassifying\u201d the records to a company-speciic or commonly used\ntaxonomy for more in-depth analytic capabilities downstream. This is particularly true\nwithin use cases such as supply chain or procurement analytics - where taxonomies\nhelp organize entities into logical groupings for business and analytic purposes. Tamr\u2019s\nclassify phase operates in the same manner as the connecting and cleaning phases\ndo, leveraging Tamr\u2019s unique blend of human-guided machine learning to rapidly and\naccurately categorize records to the deepest levels of a provided taxonomy. Within the\nclassiication phase:\n\u2022 Tamr will start with a clean, uniied dataset focused on logical entities (such as parts) that have yet to be\ncategorized to an organizational taxonomy. The irst step in the classiication process is to load the target\ntaxonomy into Tamr with sample records of entities related to each branch included - where Tamr can then\nidentify the words / tokens related to each branch of the taxonomy\n\u2022 Tamr will then apply human-guided machine learning to the uniied dataset in order to appropriately\ncategorize each record in the uniied dataset to a speciic taxonomy\n+ Tamr will proile the values within each record of the uniied dataset and use it\u2019s machine learning\nalgorithms to identify matches between words contained within values of each dataset record and\nwords associated with each category of the taxonomy. This will enable Tamr to accurately suggest a\nclassiication for each record based on the initial model it generates\n+ Tamr will then produce simple high impact questions regarding whether or not certain records, that\nare representative of a large portion of the uniied dataset records, are categorized appropriately. For\nexample, if Tamr has low conidence regarding whether or not a record pertaining to \u201c1 inch turbine\nbolts\u201d is in fact part of the \u201cBolt\u201d category within the organization\u2019s taxonomy, it will ask an expert\nwithin the client organization for their feedback - driving accuracy and enhancing future automation\n+ Expert feedback via direct login or out-of-band mechanisms such as email is then incorporated into\nthe dataset and Tamr\u2019s models in accordance with the client\u2019s expert feedback worklow\n\u2022 Once records have been classiied via Tamr\u2019s worklow, Tamr will add new ields to each uniied dataset\nrecord indicating how that record is categorized. For example, if Tamr is classifying a record to the 4th level\nof an organization\u2019s taxonomy, it will add 4 ields to each record indicating how it is categorized\nAfter classiication, the connected, cleaned, and classiied dataset is ready for consumption. Tamr is lexible in\nits consumption options via its APIs - whether it be via an analytic tool, operational database, or simple Excel /\nCSV ile. This is in large part due to the lexibility Tamr has in supporting multiple operational and analytic projects\nwithin the enterprise - as the need for centrally curated, trusted datasets of key organizational entities is\nvirtually limitless. \n\n3. Product Architecture\nThe Tamr platform is designed to take advantage of recent advances in lexibility, scalability, and ease of\nadministration. The application layer is composed of an array of loosely-coupled microservices providing a broad\narray of capabilities, while simultaneously allowing lexibility in how the application is deployed and scalability\nof individual application components. The data processing layer assembles highly scalable components to\nprovide both high-volume data processing and low-latency search and iltering. The overall system scales", "doc_id": "c5e69acb-f870-48a5-aec9-25d6fc1954c9", "embedding": null, "doc_hash": "989fb5d910896025c1170a2777d5f25c4fe86287475540b2b7cc5da9531da61f", "extra_info": null, "node_info": {"start": 12278, "end": 16259, "_node_type": "1"}, "relationships": {"1": "dc691d0f-d47d-499b-97f3-1ec02360044b", "2": "3c413978-c847-4d57-9f27-b86aca205185", "3": "b4e6e4be-4681-4f2a-b502-e3b1d2aeb1c3"}}, "__type__": "1"}, "b4e6e4be-4681-4f2a-b502-e3b1d2aeb1c3": {"__data__": {"text": "data processing and low-latency search and iltering. The overall system scales down\nto a single, modest server for trials and up to multi-node data lake infrastructure to tackle large, production\nchallenges.\nThe individual microservices that comprise the application run behind a single facade that makes them look and\nfeel like a single application to the end user. This assembly also interacts with organizational backing services,\nsuch as LDAP for user authentication, and a relational database for storing user preferences and the like. The\ndata itself stays within multi-node, scale-out infrastructure taking advantage of technologies such as HDFS for\ndistributed, reliable storage, and Spark for distributed, in-memory computation. Finally, an Elasticsearch cluster\npowers a richly interactive front end, while keeping query latency and page load time short so that users can\n\n4. Market Positioning\nTamr can operate in a variety of capacities within an enterprise\u2019s data environment - as both a system of record\nand a system of reference. The platform is designed to operate in a complementary nature to most big data\ninvestments and solve the large \u201cgarbage in, garbage out\u201d issues. Tamr is most often compared to and can\ncomplement the following technologies:\n\u2022 Data Catalogs - Tamr has some capabilities around proiling of datasets; however, dedicated data catalogs\nthat can discover datasets of interest related to a particular entity and foster secure collaboration among\nusers can enhance Tamr\u2019s value proposition downstream. The data sources discovered and analyzed within\na data catalog can serve as an input to Tamr\n\u2022 Master Data Management - While Tamr could be deployed as a de facto master data management\nsolution, it most often complements legacy master data management solutions. In particular, Tamr can help\nMDM systems by acting as a system of reference for record consolidation - making the operation faster and\nmuch more scalable\n\u2022 ETL - Much like master data management, Tamr acts as a system of reference for ETL solutions. In\nparticular, Tamr can suggest transformations for ETL solutions regarding which certain records are in fact\nreferencing the same entity - helping with the speed and scale of executing transformations\n\u2022 Self-Service Data Preparation - Tamr is complementary to self-service data preparation tools in the market.\nOften times, these tools are targeted at data sets that are fairly connected and cleaned already and no\nrobust machine learning is needed. Self-service data preparation tools do, however, allow for individual user\ndata curation (for example, eliminating unwanted records) which is a valuable downstream function of the\nTamr platform\n\u2022 Analytic Tools - Tamr is complementary to analytic and visualization tools - which can be used as a Tamr\nconsumption method. Uniied, clean datasets are critical to analytic and visualization platforms - as it solves\nthe \u201cgarbage in, garbage out\u201d dilemma that plagues most large organizations undertaking analytic initiatives\n5. Use Case Examples\nTamr\u2019s domain-agnostic approach to enterprise data uniication makes it a great it for companies across all\nverticals and applicable to a wide variety of use cases. Tamr has enabled enterprises to centrally curate data from\nsuppliers and parts to products and customers. Below are a couple of examples:\nMultinational Industrial Company (Suppliers, Parts, & Services): Tamr was working with a multinational industrial\norganization that wanted to gain enhanced visibility into their supply base - in particular what parts they were\npurchasing across the entire enterprise and from whom. This was extremely dificult to do using traditional\napproaches to integrate and clean datasets given the size and complexity of their data environment. The\ncompany approached Tamr to help with this data uniication problem and in doing so, Tamr connected and\ncleaned their procurement data (representing $60 billion in spend) across 8 business units to fuel analytic\noutcomes. The results included irst-time visibility into spend (suppliers, parts, services) that enabled the\ncompany to unlock $380+ million in cost-savings opportunities (projected", "doc_id": "b4e6e4be-4681-4f2a-b502-e3b1d2aeb1c3", "embedding": null, "doc_hash": "72943ba14da6a17840d909d9df03efc27b56418340c1a7b71fc67b11134624da", "extra_info": null, "node_info": {"start": 16228, "end": 20403, "_node_type": "1"}, "relationships": {"1": "dc691d0f-d47d-499b-97f3-1ec02360044b", "2": "c5e69acb-f870-48a5-aec9-25d6fc1954c9", "3": "f1391247-e63a-401c-8d6d-3af522e52738"}}, "__type__": "1"}, "f1391247-e63a-401c-8d6d-3af522e52738": {"__data__": {"text": "to unlock $380+ million in cost-savings opportunities (projected $500+ million), including a 10x ROI in\nYear 1\nLarge Media Company (Company Entities): Tamr had engaged with a large media company that was undertaking\nan initiative to create an enterprise-wide data model after years of growth both organically and inorganically.\nThe company sells organizational data and had an existing data integration process internally, but due to its\nheavily manual nature, it lacked the speed and scale needed to keep up with the changing environment. The\nclient needed help with record deduplication and Tamr was able to deliver highly impactful results. This included\nexpediting data integration efforts by several months while reducing the manual effort needed to integrate\ndatasets by over 40%. Finally, given Tamr\u2019s human-in-the-loop worklow, the client accomplished this while\nachieving remarkably high accuracy (precision and recall rates of over 95%)\n\nHow is Tamr Different from MDM and ETL Tools?\nBusinessman with statistic graph of stock market financial indices analysis on laptop screen, finance data and technology concept\nThere is a lot in flux with the data management industry, and naturally, it\u2019s causing confusion. Companies collect data at a rapidly expanding rate, and the old processes in place to master this data severely limit their ability to make sense of it all.\n\nAs we know, unmastered data leads to a host of problems from the inability to optimize business operations effectively to leaving you susceptible to data breaches and compliance issues. \n\nIn this blog post we review the key features of Master Data Management (MDM) solutions, compared with Extract, Transform, and Load (ETL) solutions, and discuss the benefits of Tamr cloud-native data mastering, ML-based approach for data mastering is compared to ETL and MDM.  \n\nMDM vs. ETL\nWhat are your current data mastering options and what are the pros and cons of each? Let\u2019s review:\n\nMaster Data Management (MDM): The MDM process involves creating a master record where all entities used across the organization are defined. The idea is to merge all the individual records and match that to the entity in the master record using rules to accomplish the task. Here\u2019s a few examples of what this looks like from Michael Stonebraker\u2019s 7 Tenets Of Scalable Data Unification:\n\n\u201cDick\u201d matches \u201cRichard\u201d in the name field\n-99 matches null in the salary field\nIf systems A and B have different values for address, then use the one from system A\nMDM Pros: MDM provides a \u201cgolden record\u201d, which is meant to be the \u201csource of truth\u201d about an entity that other sources can reference downstream. These systems also provide insight into the lineage of these records and flexibility in defining how these records are created. In theory, when done without errors, you should have no issue with duplicates or unmatched data, and be able to provide consumption tools with an accurate view of each entity.\n\nMDM Cons: You\u2019re relying on a rules-based golden record, which requires a human-intensive process to deliver. This is not scalable and is dependent upon continuous, manual review of exceptions. Because of this, you will not only leave a large portion of your data unmastered, but you also pay a premium in resource costs to leave yourself susceptible to human error.\n\nExtract, Transform, & Load (ETL): The ETL method is a widely adopted data mastering process that\u2019s been around for 20+ years. It involves creating a global schema up front using a programmer to understand how the schema is used and writing conversion routines, cleaning and transformation routines, and continuously updating it over time to ensure accuracy.\n\nETL Pros: ETL is a very effective way to move data, and can also be used to perform mastering when simple rules will suffice (e.g., \u201cInc.\u201d equals \u201cIncorporated\u201d).\n\nETL Cons: It\u2019s impossible to scale using ETL since it\u2019s so laborious in nature. This", "doc_id": "f1391247-e63a-401c-8d6d-3af522e52738", "embedding": null, "doc_hash": "d021ad52e3ce55391f15965c2cbfdddd79479331b9edb335717015c82689dfd2", "extra_info": null, "node_info": {"start": 20415, "end": 24351, "_node_type": "1"}, "relationships": {"1": "dc691d0f-d47d-499b-97f3-1ec02360044b", "2": "b4e6e4be-4681-4f2a-b502-e3b1d2aeb1c3", "3": "808b7731-8096-4c64-9a9f-ed269188e5e0"}}, "__type__": "1"}, "808b7731-8096-4c64-9a9f-ed269188e5e0": {"__data__": {"text": "impossible to scale using ETL since it\u2019s so laborious in nature. This is not a viable option for companies that collect a large (and continuously growing) amount of data. ETL is also not designed to deliver a golden record, a key output of the mastering process that is necessary to drive consistency across consumption points.\n\nIt\u2019s hard to believe that MDM and ETL are the most widely used data mastering processes given their inability to scale. For years, companies have had to settle for not being able to leverage a large portion of their data until now.\n\nThe Modern, Agile Solution to Data Mastering\nHaving a platform that allows for complete data unification is the solution to data mastering at scale. It works by taking your data from all facets of the business and unifying it by using a combination of machine learning and human expertise. It\u2019s the solution to MDM and ETL shortcomings, allowing companies to master all of their data in an efficient and effective manner.\n\nSome platforms (like Tamr) even use machine learning and automation to continually evolve and update as your data changes and grows.\n\nJust how big of an impact can a data mastering platform like Tamr having on your bottom line? For tech giant GE, it meant a savings of 80 million.\n\nThe Advantage of Cloud-Native Master Data Management by Tamr\nTamr differs from traditional data tools like MDM and ETL by using an agile approach to tackle data mastering, as well as leveraging the scalability of a cloud-native data mastering implementation. Learn more how Tamr\u2019s approach is different than traditional MDMs, like Informatica.\n\nAs we all know, agile completely transformed software development, and it\u2019s set to do the same with data thanks to Tamr.\n\nBridging the Gap Between Data and Analytics \nTamr connects internal and external datasets (including datasets from various CRM and ERP systems, external reference data aggregators and third-party datasets). It uses proprietary machine learning technology to produce higher quality, up-to-date, curated datasets for downstream analytics programs. Tamr\u2019s output is clean, consolidated data that can then be used to power visualization tools such as PowerBI, Qlik, Tableau, and Thoughtspot. In addition, Tamr\u2019s technology engages data experts effectively through simple yes/no questions to provide feedback on data outliers and train the ML models to meet unique business needs, driving higher data accuracy and bridging the gap between data and analytic outcomes.", "doc_id": "808b7731-8096-4c64-9a9f-ed269188e5e0", "embedding": null, "doc_hash": "5b456a8067f60a2566e3080ebb0a9cf3d54c2b3c9508f743b2a4777a75cb4159", "extra_info": null, "node_info": {"start": 24339, "end": 26834, "_node_type": "1"}, "relationships": {"1": "dc691d0f-d47d-499b-97f3-1ec02360044b", "2": "f1391247-e63a-401c-8d6d-3af522e52738"}}, "__type__": "1"}}}